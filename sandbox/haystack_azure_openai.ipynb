{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8efb045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haystack-ai in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (2.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: haystack-experimental in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (0.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.1.4)\n",
      "Requirement already satisfied: lazy-imports in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (10.5.0)\n",
      "Requirement already satisfied: networkx in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.2.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (1.54.3)\n",
      "Requirement already satisfied: pandas in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.2.3)\n",
      "Requirement already satisfied: posthog in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (8.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm->haystack-ai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->haystack-ai) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->haystack-ai) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->haystack-ai) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from posthog->haystack-ai) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from posthog->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install haystack-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ec44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dot_env import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_DEPLOYMENT = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b667f92",
   "metadata": {},
   "source": [
    "# Embedding Models\n",
    "You can leverage embedding models from Azure OpenAI through two components: `AzureOpenAITextEmbedder` and `AzureOpenAIDocumentEmbedder`.\n",
    "\n",
    "To create semantic embeddings for documents, use `AzureOpenAIDocumentEmbedder` in your indexing pipeline. For generating embeddings for queries, use `AzureOpenAITextEmbedder`. Once you’ve selected the suitable component for your specific use case, initialize the component with required parameters.\n",
    "\n",
    "Below is the example indexing pipeline with `InMemoryDocumentStore`, `AzureOpenAIDocumentEmbedder` and `DocumentWriter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484ba44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Texts: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': {'model': 'text-embedding-ada-002',\n",
       "   'usage': {'prompt_tokens': 20, 'total_tokens': 20}}},\n",
       " 'writer': {'documents_written': 3}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders import AzureOpenAITextEmbedder, AzureOpenAIDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "document_store = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "\n",
    "documents = [Document(content=\"My name is Wolfgang and I live in Berlin\"),\n",
    "             Document(content=\"I saw a black horse running\"),\n",
    "             Document(content=\"Germany has many big cities\")]\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"embedder\", AzureOpenAIDocumentEmbedder(azure_deployment=\"text-embedding-ada-002\"))\n",
    "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "\n",
    "indexing_pipeline.run({\"embedder\": {\"documents\": documents}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82fb588",
   "metadata": {},
   "source": [
    "# Generative Models (LLMs)\n",
    "You can leverage Azure OpenAI models through two components: `AzureOpenAIGenerator` and `AzureOpenAIChatGenerator`.\n",
    "\n",
    "To use OpenAI models deployed through Azure services for text generation, initialize a `AzureOpenAIGenerator` with `azure_deployment` and `azure_endpoint`. You can then use the `AzureOpenAIGenerator` instance in a pipeline after the `PromptBuilder`.\n",
    "\n",
    "Below is the example of generative questions answering pipeline using RAG with `PromptBuilder` and `AzureOpenAIGenerator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce09c8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AzureOpenAIChatGenerator' from 'haystack.components.generators' (c:\\sw\\anaconda3\\envs\\torch\\Lib\\site-packages\\haystack\\components\\generators\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01min_memory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryBM25Retriever\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptBuilder\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIChatGenerator\n\u001b[0;32m      6\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mGiven the following information, answer the question.\u001b[39m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124mQuestion: What\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the official language of \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m country }}?\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     16\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AzureOpenAIChatGenerator' from 'haystack.components.generators' (c:\\sw\\anaconda3\\envs\\torch\\Lib\\site-packages\\haystack\\components\\generators\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import AzureOpenAIChatGenerator, AzureOpenAIGenerator\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context: \n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: What's the official language of {{ country }}?\n",
    "\"\"\"\n",
    "pipe = Pipeline()\n",
    "\n",
    "pipe.add_component(\"retriever\", InMemoryBM25Retriever(document_store=document_store))\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\"llm\", AzureOpenAIGenerator(azure_deployment=OPENAI_DEPLOYMENT))\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "pipe.run({\n",
    "    \"retriever\": {\"query\": \"What's the official language of {{ country }}?\"},\n",
    "    \"prompt_builder\": {\n",
    "        \"country\": \"France\"\n",
    "    }\n",
    "})   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77937e",
   "metadata": {},
   "source": [
    "Intento de Chat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = AzureOpenAIChatGenerator(azure_deployment=OPENAI_DEPLOYMENT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
