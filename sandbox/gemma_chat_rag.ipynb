{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8Q51pZ5NI0L"
   },
   "source": [
    "# Build with Gemma and Haystack 2.x\n",
    "\n",
    "<img src=\"https://huggingface.co/blog/assets/gemma/Gemma-logo-small.png\" width=\"200\" style=\"display:inline;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img src=\"https://haystack.deepset.ai/images/haystack-ogimage.png\" width=\"430\" style=\"display:inline;\">\n",
    "\n",
    "\n",
    "\n",
    "We will see what we can build with the new [Google Gemma open models](https://blog.google/technology/developers/gemma-open-models/) and the [Haystack LLM framework](https://haystack.deepset.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LRwBMJdF_d1"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5ggXrtFs18rs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: haystack-ai in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: google-ai-haystack in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: wikipedia in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (1.4.0)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: haystack-experimental in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (0.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.1.4)\n",
      "Requirement already satisfied: lazy-imports in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (0.3.1)\n",
      "Requirement already satisfied: more-itertools in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (10.5.0)\n",
      "Requirement already satisfied: networkx in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.2.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (1.54.3)\n",
      "Requirement already satisfied: pandas in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.2.3)\n",
      "Requirement already satisfied: posthog in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (8.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from haystack-ai) (4.11.0)\n",
      "Requirement already satisfied: google-generativeai>=0.3.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-ai-haystack) (0.8.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from rich) (2.18.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (2.22.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (5.28.3)\n",
      "Requirement already satisfied: pydantic in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-generativeai>=0.3.1->google-ai-haystack) (2.9.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai>=0.3.1->google-ai-haystack) (1.25.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->haystack-ai) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm->haystack-ai) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->haystack-ai) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->haystack-ai) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->haystack-ai) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from posthog->haystack-ai) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from posthog->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-core->google-generativeai>=0.3.1->google-ai-haystack) (1.65.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.1->google-ai-haystack) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.1->google-ai-haystack) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.1->google-ai-haystack) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic->google-generativeai>=0.3.1->google-ai-haystack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic->google-generativeai>=0.3.1->google-ai-haystack) (2.23.4)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.3.1->google-ai-haystack) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.3.1->google-ai-haystack) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.3.1->google-ai-haystack) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.3.1->google-ai-haystack) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai>=0.3.1->google-ai-haystack) (1.67.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.1->google-ai-haystack) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\sw\\anaconda3\\envs\\torch\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.3.1->google-ai-haystack) (0.6.1)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown-it.exe is installed in 'c:\\sw\\anaconda3\\envs\\torch\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install haystack-ai google-ai-haystack wikipedia rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh60ZvTdGDdh"
   },
   "source": [
    "## Authorization\n",
    "\n",
    "- you need an Hugging Face account\n",
    "- you need to accept Google conditions here: https://huggingface.co/google/gemma-7b-it and wait for the authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lBjYZOC3Ug2",
    "outputId": "1395a3e3-2ce5-48ba-e3cc-148f99a000f8"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "from dot_env import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfW8gRwpGZjc"
   },
   "source": [
    "## Chat with Gemma (travel assistant) ðŸ›©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```curl \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\"contents\":[{\"parts\":[{\"text\":\"Explain how AI works\"}]}]}' \\\n",
    "  -X POST 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=YOUR_API_KEY'```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack_integrations.components.generators.google_ai.chat.gemini.GoogleAIGeminiChatGenerator object at 0x0000024B02AE78F0>\n",
       "Inputs:\n",
       "  - messages: List[ChatMessage]\n",
       "  - streaming_callback: Optional[Callable[]]\n",
       "Outputs:\n",
       "  - replies: List[ChatMessage]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.utils import Secret\n",
    "from haystack_integrations.components.generators.google_ai import GoogleAIGeminiGenerator, GoogleAIGeminiChatGenerator\n",
    "\n",
    "from dot_env import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "generator = GoogleAIGeminiChatGenerator(model=\"gemini-1.5-flash-latest\")\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a large language model, I don't have personal interests or opinions. I'm designed to process information and respond to queries in a helpful and informative way. So, I can't really say what the \"most interesting\" thing I know is, because that would be subjective.\n",
      "\n",
      "However, I can share some fascinating facts that I've learned:\n",
      "\n",
      "* **The human brain contains more connections than there are stars in the Milky Way galaxy.** That's a lot of information processing power!\n",
      "* **The Earth's atmosphere is constantly being bombarded by meteoroids.** Most are tiny, but some can be quite large.\n",
      "* **There are more trees on Earth than stars in the Milky Way.** That's a lot of trees!\n",
      "* **The universe is expanding at an accelerating rate.** This means that galaxies are moving further apart from each other over time.\n",
      "* **There is a planet out there that is made entirely of diamonds.** It's called 55 Cancri e and it's twice the size of Earth.\n",
      "\n",
      "These are just a few examples of the many interesting things I've learned. If you're interested in a particular topic, I can provide you with more information about it. \n",
      "\n",
      "Ultimately, what you find interesting is up to you! What kind of things are you curious about? I'd be happy to learn more about them with you. \n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "res = generator.run(messages = [ChatMessage.from_user(\"What is the most interesting thing you know?\")])\n",
    "for answer in res[\"replies\"]:\n",
    "    print(answer.content)\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– That sounds amazing!  To help me find the perfect Hawaii vacation for you, tell me a little more about what you're looking for. \n",
      "\n",
      "* **What kind of holiday experience are you hoping for?** Relaxing on the beach, exploring nature, trying new foods, or something else entirely? \n",
      "* **Who are you traveling with?**  A partner, friends, family, or solo?\n",
      "* **What's your budget like?**  This will help me recommend the best options for your trip.\n",
      "* **What kind of accommodation are you looking for?**  Luxury resort, cozy condo, or something else?\n",
      "* **Are there any specific islands you're interested in?** Or are you open to exploring all of them?\n",
      "\n",
      "The more information you give me, the better I can tailor your dream Hawaii vacation! \n",
      "\n",
      "ðŸ¤– Okay, so you're looking for a mix of relaxation and nightlife! That's a great combination.  To help narrow down the options, do you have any preference on the following:\n",
      "\n",
      "* **Island:**  Do you have a specific island in mind, or are you open to exploring different ones? Each island has a unique vibe and nightlife scene. \n",
      "* **Budget:** Are you looking for a luxury experience or something more budget-friendly?  \n",
      "* **Type of party:** Are you looking for a laid-back beach bar scene, a more vibrant club scene, or a mix of both? \n",
      "\n",
      "Once I understand these details, I can recommend the perfect island and accommodation for your holiday! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [ChatMessage.from_system(\"You are a travel agent and I am a customer looking for a vacation. Can you help me?\")]\n",
    "\n",
    "while True:\n",
    "  msg = input(\"Enter your message or Q to exit\\nðŸ§‘ \")\n",
    "  if msg==\"Q\":\n",
    "    break\n",
    "  messages.append(ChatMessage.from_user(msg))\n",
    "  response = generator.run(messages=messages)\n",
    "  assistant_resp = response['replies'][0]\n",
    "  print(\"ðŸ¤– \"+assistant_resp.content)\n",
    "  messages.append(assistant_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XAtaoEiHE6B"
   },
   "source": [
    "## RAG with Gemma (about Rock music) ðŸŽ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCeqQB3kHqcz"
   },
   "source": [
    "### Load data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "c_yp6s9aHnhx"
   },
   "outputs": [],
   "source": [
    "favourite_bands=\"\"\"Audioslave\n",
    "Blink-182\n",
    "Dire Straits\n",
    "Evanescence\n",
    "Green Day\n",
    "Muse (band)\n",
    "Nirvana (band)\n",
    "Sum 41\n",
    "The Cure\n",
    "The Smiths\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Uu9PclysIP4T"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from pprint import pprint\n",
    "import rich\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpTwStuJHvxR"
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "raw_docs=[]\n",
    "\n",
    "for title in favourite_bands:\n",
    "    page = wikipedia.page(title=title, auto_suggest=False)\n",
    "    doc = Document(content=page.content, meta={\"title\": page.title, \"url\":page.url})\n",
    "    raw_docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1fvmgsZH0i8"
   },
   "source": [
    "### Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MHVRdvRNHwKT"
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EoJjHmLjH7Ag"
   },
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBbmbJX6H9cj",
    "outputId": "51722cec-701a-47be-b9f7-b2815d92cd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000024B1F0A7530>\n",
       "ðŸš… Components\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing = Pipeline()\n",
    "indexing.add_component(\"cleaner\", DocumentCleaner())\n",
    "indexing.add_component(\"splitter\", DocumentSplitter(split_by='sentence', split_length=2))\n",
    "indexing.add_component(\"writer\", DocumentWriter(document_store=document_store, policy=DuplicatePolicy.OVERWRITE))\n",
    "\n",
    "indexing.connect(\"cleaner\", \"splitter\")\n",
    "indexing.connect(\"splitter\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddizanfoIFz3",
    "outputId": "03da6778-fa99-4ff2-c9f4-865c6cc5b7cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 1610}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing.run({\"cleaner\":{\"documents\":raw_docs}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRv-TgV9IZcF",
    "outputId": "92b55c9a-2b89-4740-c512-864d3c210cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Audioslave',\n",
       " 'url': 'https://en.wikipedia.org/wiki/Audioslave',\n",
       " 'source_id': 'cf53c7ec310b6c605f6528b4edb9698b78896db7725e19e65c86ee6a871d5e10',\n",
       " 'page_number': 1,\n",
       " 'split_id': 0,\n",
       " 'split_idx_start': 0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.filter_documents()[0].meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk8v_s8xIdLV"
   },
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wF7mPcnwIbfi"
   },
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<start_of_turn>user\n",
    "Using the information contained in the context, give a comprehensive answer to the question.\n",
    "If the answer is contained in the context, also report the source URL.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "\n",
    "Context:\n",
    "  {% for doc in documents %}\n",
    "  {{ doc.content }} URL:{{ doc.meta['url'] }}\n",
    "  {% endfor %};\n",
    "  Question: {{query}}<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx6PNcm-I1zF",
    "outputId": "a68372ad-8936-4197-e972-1d81c54a5404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000024B02F0F3E0>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: GoogleAIGeminiGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.parts (str)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "\n",
    "generator = GoogleAIGeminiGenerator(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "rag = Pipeline()\n",
    "rag.add_component(\"retriever\", InMemoryBM25Retriever(document_store=document_store, top_k=5))\n",
    "rag.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag.add_component(\"llm\", generator)\n",
    "\n",
    "rag.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "rag.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrKccbWeMyjB"
   },
   "source": [
    "### Let's ask some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "kUsZ5NPzKCEO"
   },
   "outputs": [],
   "source": [
    "def get_generative_answer(query, rag_model=rag):\n",
    "\n",
    "  results = rag_model.run({\n",
    "      \"retriever\": {\"query\": query},\n",
    "      \"prompt_builder\": {\"query\": query}\n",
    "    }\n",
    "  )\n",
    "\n",
    "  answer = results[\"llm\"][\"replies\"][0]\n",
    "  rich.print(answer)\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "96f13cf06a814cae878244f42aefecbb",
      "6d14f15aa8bb4422af36f3603ec29dab",
      "455cc132a0de4967ac8064d8a68584b2",
      "cd5c0ba2ab1a453993ceeed76fe71bf8",
      "52ef4fd4cc2d49b6803995ee56369816",
      "e21d0fd8e3ca4b96b96d5eb0471efd38",
      "5ca2615632184ccb908628b62f2e8bbe",
      "8bac2d79ecb94883ba8b5c41bd827f3d",
      "23206a144ea9409a9850fdba5257d1d8",
      "b9c0b15ab5a54ef393d32f11f115ffcc",
      "5a679669b6ae4a26b4b9408d049529af"
     ]
    },
    "id": "LXxvLGuNKrKK",
    "outputId": "73850d48-d0cf-4cec-ebc6-0101690053f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Audioslave was formed by members of Soundgarden and Rage Against the Machine. \n",
       "\n",
       "Audioslave's music drew heavily from the musical influences of its members' previous bands, incorporating the \n",
       "grunge sound of Soundgarden and the funk metal sound of Rage Against the Machine.  The band also drew inspiration \n",
       "from 1970s hard rock and heavy metal bands like Led Zeppelin and Black Sabbath. \n",
       "\n",
       "<span style=\"font-weight: bold\">[</span>Source: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://en.wikipedia.org/wiki/Audioslave</span><span style=\"font-weight: bold\">]</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Audioslave was formed by members of Soundgarden and Rage Against the Machine. \n",
       "\n",
       "Audioslave's music drew heavily from the musical influences of its members' previous bands, incorporating the \n",
       "grunge sound of Soundgarden and the funk metal sound of Rage Against the Machine.  The band also drew inspiration \n",
       "from 1970s hard rock and heavy metal bands like Led Zeppelin and Black Sabbath. \n",
       "\n",
       "\u001b[1m[\u001b[0mSource: \u001b[4;94mhttps://en.wikipedia.org/wiki/Audioslave\u001b[0m\u001b[1m]\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Audioslave was formed by members of Soundgarden and Rage Against the Machine. \\n\\nAudioslave's music drew heavily from the musical influences of its members' previous bands, incorporating the grunge sound of Soundgarden and the funk metal sound of Rage Against the Machine.  The band also drew inspiration from 1970s hard rock and heavy metal bands like Led Zeppelin and Black Sabbath. \\n\\n[Source: https://en.wikipedia.org/wiki/Audioslave] \\n\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generative_answer(\"Audioslave was formed by members of two iconic bands. Can you name the bands and discuss the sound of Audioslave in comparison?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "UsS-w7DSKvVN"
   },
   "outputs": [],
   "source": [
    "nice_questions_to_try=\"\"\"What was the original name of Sum 41?\n",
    "What was the title of Nirvana's breakthrough album released in 1991?\n",
    "Green Day's \"American Idiot\" is a rock opera. What's the story it tells?\n",
    "Audioslave was formed by members of two iconic bands. Can you name the bands and discuss the sound of Audioslave in comparison?\n",
    "Evanescence's \"Bring Me to Life\" features a male vocalist. Who is he, and how does his voice complement Amy Lee's in the song?\n",
    "What is Sum 41's debut studio album called?\n",
    "Who was the lead singer of Audioslave?\n",
    "When was Nirvana's first studio album, \"Bleach,\" released?\n",
    "Were the Smiths an influential band?\n",
    "What is the name of Evanescence's debut album?\n",
    "Which band was Morrissey the lead singer of before he formed The Smiths?\n",
    "Dire Straits' hit song \"Money for Nothing\" features a guest vocal by a famous artist. Who is this artist?\n",
    "Who played the song \"Like a stone\"?\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "8e94c1f8262c46a5a46f4eb629188557",
      "9708a7a3233a4e519e729d7541ca207c",
      "edd419577fd648199e1145ae0c747a8f",
      "99f30cdec3074192a6f57005fbda7ae2",
      "6c178969648d455ea63722df7453ae3e",
      "4985c6a71c00480b803dfc60332c3506",
      "8ba060081bca4f62b0e9c71274d91b1a",
      "9fdc592ff60648ffbc9eb533a07c66a7",
      "c148d084abf84b338f42d12c302ba35b",
      "e8f39ef33c24475387672521c4e0d40c",
      "0157d75798fe48e8b7e58538e8d99065"
     ]
    },
    "id": "rnXFXEQMLijI",
    "outputId": "b84efcb4-f0fb-4ade-b6ce-a7bd6c8fd8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Sum 41's debut studio album called?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sum <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>'s debut studio album is called **All Killer No Filler**. \n",
       "\n",
       "This information is found in the context: <span style=\"color: #008000; text-decoration-color: #008000\">\"The band released its debut album, All Killer No Filler, in 2001.\"</span> - \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://en.wikipedia.org/wiki/Sum_41)</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sum \u001b[1;36m41\u001b[0m's debut studio album is called **All Killer No Filler**. \n",
       "\n",
       "This information is found in the context: \u001b[32m\"The band released its debut album, All Killer No Filler, in 2001.\"\u001b[0m - \n",
       "\u001b[1m(\u001b[0m\u001b[4;94mhttps://en.wikipedia.org/wiki/Sum_41\u001b[0m\u001b[4;94m)\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Sum 41\\'s debut studio album is called **All Killer No Filler**. \\n\\nThis information is found in the context: \"The band released its debut album, All Killer No Filler, in 2001.\" - [https://en.wikipedia.org/wiki/Sum_41](https://en.wikipedia.org/wiki/Sum_41) \\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=random.choice(nice_questions_to_try)\n",
    "print(q)\n",
    "get_generative_answer(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The provided context does not contain information about Coldplay's musical style. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The provided context does not contain information about Coldplay's musical style. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The provided context does not contain information about Coldplay's musical style. \\n\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generative_answer(\"What type of music plays Coldplay?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I'm sorry, but the context does not contain any information about what is considered the <span style=\"color: #008000; text-decoration-color: #008000\">\"most interesting\"</span> thing. \n",
       "It only provides details about specific bands and their music. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I'm sorry, but the context does not contain any information about what is considered the \u001b[32m\"most interesting\"\u001b[0m thing. \n",
       "It only provides details about specific bands and their music. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, but the context does not contain any information about what is considered the \"most interesting\" thing. It only provides details about specific bands and their music. \\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generative_answer(\"What is the most interesting thing you know?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_prompt_template = \"\"\"\n",
    "<start_of_turn>user\n",
    "Decide if the following answer is consistent with the corresponding sources. Note that \n",
    "consistency means all information in the answer is supported by the sources.\n",
    "\n",
    "Sources: [\n",
    "  {% for doc in documents %}\n",
    "  {{ doc.content }} URL:{{ doc.meta['url'] }}\n",
    "  {% endfor %};\n",
    "]\n",
    "Answer: [{{answer}}]\n",
    "\n",
    "Explain your reasoning step by step then answer (yes or no) the question.<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "critic_prompt_builder = PromptBuilder(template=critic_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000024B20358140>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: GoogleAIGeminiGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.parts (str)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = GoogleAIGeminiGenerator(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "critic_rag = Pipeline()\n",
    "critic_rag.add_component(\"retriever\", InMemoryBM25Retriever(document_store=document_store, top_k=5))\n",
    "critic_rag.add_component(\"prompt_builder\", critic_prompt_builder)\n",
    "critic_rag.add_component(\"llm\", generator)\n",
    "\n",
    "critic_rag.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "critic_rag.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Green_Day\t You won't know what hit you. American Idiot knows no limitsâ€”it's a global knockout.\n",
      "https://en.wikipedia.org/wiki/Evanescence\t The label flew them to New York, and told them that they loved their different sound and thought they had potential, but \"we don't really totally know what to do with you\", Lee recalled. They were then told, \"if you were this good while distracted by school and all this other stuff, how good will you be if we put you in an environment where you have nothing to do but write and be influenced by your surroundings, like in Los Angeles.\n",
      "https://en.wikipedia.org/wiki/The_Smiths\t In October, Marr said on BBC Radio 5 Live: \"Stranger things have happened so, you know, who knows? ..\n",
      "https://en.wikipedia.org/wiki/Green_Day\t Green Day has covered HÃ¼sker DÃ¼'s \"Don't Want to Know If You Are Lonely\" as a B-side to the \"Warning\" single, and the character \"Mr. Whirly\" in the group's song \"Misery\" is a reference to the Replacements song of the same name.\n",
      "https://en.wikipedia.org/wiki/Sum_41\t The episode included an interview with program host Nic Harcourt.\n",
      "\"Baby You Don't Wanna Know\" was released as the album's second single.\n"
     ]
    }
   ],
   "source": [
    "retriever = InMemoryBM25Retriever(document_store=document_store, top_k=5)\n",
    "for doc in retriever.run(query=\"What is the most interesting thing you know?\")['documents']:\n",
    "    print(f\"{doc.meta['url']}\\t{doc.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which band was Morrissey the lead singer of before he formed The Smiths?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The provided context does not contain information about a band Morrissey was in before forming The Smiths. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The provided context does not contain information about a band Morrissey was in before forming The Smiths. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Critic answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Critic answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The answer claims that the context doesn't contain information about a band Morrissey was in before The Smiths. \n",
       "\n",
       "* **Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>:** We need to check if the provided sources contain information about Morrissey being in a band before \n",
       "The Smiths.\n",
       "* **Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>:** The sources state that Morrissey and Johnny Marr formed the songwriting partnership for The Smiths. \n",
       "This implies that Morrissey wasn't in any other band before forming The Smiths. \n",
       "* **Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>:**  The sources provide no information that contradicts this.\n",
       "\n",
       "**Reasoning:** The answer correctly states that the context does not contain information about a band Morrissey was\n",
       "in before forming The Smiths.\n",
       "\n",
       "**Answer:** Yes \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The answer claims that the context doesn't contain information about a band Morrissey was in before The Smiths. \n",
       "\n",
       "* **Step \u001b[1;36m1\u001b[0m:** We need to check if the provided sources contain information about Morrissey being in a band before \n",
       "The Smiths.\n",
       "* **Step \u001b[1;36m2\u001b[0m:** The sources state that Morrissey and Johnny Marr formed the songwriting partnership for The Smiths. \n",
       "This implies that Morrissey wasn't in any other band before forming The Smiths. \n",
       "* **Step \u001b[1;36m3\u001b[0m:**  The sources provide no information that contradicts this.\n",
       "\n",
       "**Reasoning:** The answer correctly states that the context does not contain information about a band Morrissey was\n",
       "in before forming The Smiths.\n",
       "\n",
       "**Answer:** Yes \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_critic_answer(query, rag_model=rag, critic_model=critic_rag):\n",
    "  rich.print(\"Model answer: \")\n",
    "  answer = get_generative_answer(query, rag_model)\n",
    "  \n",
    "  results = critic_model.run({\n",
    "      \"retriever\": {\"query\": query},\n",
    "      \"prompt_builder\": {\"answer\": answer}\n",
    "    }\n",
    "  )\n",
    "  rich.print(\"Critic answer: \")\n",
    "  answer = results[\"llm\"][\"replies\"][0]\n",
    "  rich.print(answer)\n",
    "\n",
    "\n",
    "q=random.choice(nice_questions_to_try)\n",
    "print(q)\n",
    "get_critic_answer(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I am sorry, but the context provided does not have an answer to your question. The information contained in the \n",
       "context only provides details about bands, their releases, and how they came to be. It does not discuss any \n",
       "particular interesting fact. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I am sorry, but the context provided does not have an answer to your question. The information contained in the \n",
       "context only provides details about bands, their releases, and how they came to be. It does not discuss any \n",
       "particular interesting fact. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Critic answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Critic answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The answer states that the provided context does not have an answer to the question because it only provides \n",
       "details about bands and their releases. This is accurate as the sources discuss bands like Green Day, Evanescence, \n",
       "The Smiths, and Sum <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, mentioning their albums, singles, and some behind-the-scenes information. They don't \n",
       "contain an explicit statement or fact that could be considered <span style=\"color: #008000; text-decoration-color: #008000\">\"interesting\"</span> in a general sense.\n",
       "\n",
       "**Reasoning:**\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The answer claims the context lacks an answer to the question.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The question asks for a specific <span style=\"color: #008000; text-decoration-color: #008000\">\"interesting fact\"</span>.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. The sources only contain information about bands, their releases, and some background stories.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. There is no specific <span style=\"color: #008000; text-decoration-color: #008000\">\"interesting fact\"</span> explicitly stated in the sources.\n",
       "\n",
       "**Answer:** Yes \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The answer states that the provided context does not have an answer to the question because it only provides \n",
       "details about bands and their releases. This is accurate as the sources discuss bands like Green Day, Evanescence, \n",
       "The Smiths, and Sum \u001b[1;36m41\u001b[0m, mentioning their albums, singles, and some behind-the-scenes information. They don't \n",
       "contain an explicit statement or fact that could be considered \u001b[32m\"interesting\"\u001b[0m in a general sense.\n",
       "\n",
       "**Reasoning:**\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. The answer claims the context lacks an answer to the question.\n",
       "\u001b[1;36m2\u001b[0m. The question asks for a specific \u001b[32m\"interesting fact\"\u001b[0m.\n",
       "\u001b[1;36m3\u001b[0m. The sources only contain information about bands, their releases, and some background stories.\n",
       "\u001b[1;36m4\u001b[0m. There is no specific \u001b[32m\"interesting fact\"\u001b[0m explicitly stated in the sources.\n",
       "\n",
       "**Answer:** Yes \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_critic_answer(\"What is the most interesting thing you know?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsafe prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000024B208ED430>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: GoogleAIGeminiGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.parts (str)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "unsafe_prompt_template = \"\"\"\n",
    "<start_of_turn>user\n",
    "Using the information contained in the context, give a comprehensive answer to the question.\n",
    "If the answer is contained in the context, also report the source URL.\n",
    "If you don't know the answer, tell me a joke instead.\n",
    "\n",
    "\n",
    "Context:\n",
    "  {% for doc in documents %}\n",
    "  {{ doc.content }} URL:{{ doc.meta['url'] }}\n",
    "  {% endfor %};\n",
    "  Question: {{query}}<end_of_turn>\n",
    "\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "unsafe_prompt_builder = PromptBuilder(template=unsafe_prompt_template)\n",
    "unsafe_generator = GoogleAIGeminiGenerator(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "unsafe_rag = Pipeline()\n",
    "unsafe_rag.add_component(\"retriever\", InMemoryBM25Retriever(document_store=document_store, top_k=5))\n",
    "unsafe_rag.add_component(\"prompt_builder\", unsafe_prompt_builder)\n",
    "unsafe_rag.add_component(\"llm\", unsafe_generator)\n",
    "\n",
    "unsafe_rag.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "unsafe_rag.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why don't scientists trust atoms? Because they make up everything! \n",
       "\n",
       "I can't answer your question based on the provided context. The information focuses on specific bands and their \n",
       "music, but doesn't contain anything about <span style=\"color: #008000; text-decoration-color: #008000\">\"the most interesting thing\"</span> in a general sense. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why don't scientists trust atoms? Because they make up everything! \n",
       "\n",
       "I can't answer your question based on the provided context. The information focuses on specific bands and their \n",
       "music, but doesn't contain anything about \u001b[32m\"the most interesting thing\"\u001b[0m in a general sense. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Why don\\'t scientists trust atoms? Because they make up everything! \\n\\nI can\\'t answer your question based on the provided context. The information focuses on specific bands and their music, but doesn\\'t contain anything about \"the most interesting thing\" in a general sense. \\n'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generative_answer(\"What is the most interesting thing you know?\", rag_model=unsafe_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why don't scientists trust atoms? Because they make up everything! \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why don't scientists trust atoms? Because they make up everything! \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Critic answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Critic answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The answer is a joke and does not contain any information related to the provided sources.  Therefore, it is not \n",
       "consistent.\n",
       "\n",
       "**Answer: no** \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The answer is a joke and does not contain any information related to the provided sources.  Therefore, it is not \n",
       "consistent.\n",
       "\n",
       "**Answer: no** \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_critic_answer(\"What is the most interesting thing you know?\", rag_model=unsafe_rag, critic_model=critic_rag)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0157d75798fe48e8b7e58538e8d99065": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23206a144ea9409a9850fdba5257d1d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "455cc132a0de4967ac8064d8a68584b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bac2d79ecb94883ba8b5c41bd827f3d",
      "max": 1565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23206a144ea9409a9850fdba5257d1d8",
      "value": 1565
     }
    },
    "4985c6a71c00480b803dfc60332c3506": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52ef4fd4cc2d49b6803995ee56369816": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a679669b6ae4a26b4b9408d049529af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ca2615632184ccb908628b62f2e8bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c178969648d455ea63722df7453ae3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d14f15aa8bb4422af36f3603ec29dab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e21d0fd8e3ca4b96b96d5eb0471efd38",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5ca2615632184ccb908628b62f2e8bbe",
      "value": "Rankingâ€‡byâ€‡BM25...:â€‡100%"
     }
    },
    "8ba060081bca4f62b0e9c71274d91b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bac2d79ecb94883ba8b5c41bd827f3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e94c1f8262c46a5a46f4eb629188557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9708a7a3233a4e519e729d7541ca207c",
       "IPY_MODEL_edd419577fd648199e1145ae0c747a8f",
       "IPY_MODEL_99f30cdec3074192a6f57005fbda7ae2"
      ],
      "layout": "IPY_MODEL_6c178969648d455ea63722df7453ae3e"
     }
    },
    "96f13cf06a814cae878244f42aefecbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d14f15aa8bb4422af36f3603ec29dab",
       "IPY_MODEL_455cc132a0de4967ac8064d8a68584b2",
       "IPY_MODEL_cd5c0ba2ab1a453993ceeed76fe71bf8"
      ],
      "layout": "IPY_MODEL_52ef4fd4cc2d49b6803995ee56369816"
     }
    },
    "9708a7a3233a4e519e729d7541ca207c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4985c6a71c00480b803dfc60332c3506",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8ba060081bca4f62b0e9c71274d91b1a",
      "value": "Rankingâ€‡byâ€‡BM25...:â€‡100%"
     }
    },
    "99f30cdec3074192a6f57005fbda7ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8f39ef33c24475387672521c4e0d40c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0157d75798fe48e8b7e58538e8d99065",
      "value": "â€‡1565/1565â€‡[00:00&lt;00:00,â€‡27387.90â€‡docs/s]"
     }
    },
    "9fdc592ff60648ffbc9eb533a07c66a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9c0b15ab5a54ef393d32f11f115ffcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c148d084abf84b338f42d12c302ba35b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cd5c0ba2ab1a453993ceeed76fe71bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9c0b15ab5a54ef393d32f11f115ffcc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5a679669b6ae4a26b4b9408d049529af",
      "value": "â€‡1565/1565â€‡[00:00&lt;00:00,â€‡14446.98â€‡docs/s]"
     }
    },
    "e21d0fd8e3ca4b96b96d5eb0471efd38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f39ef33c24475387672521c4e0d40c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edd419577fd648199e1145ae0c747a8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fdc592ff60648ffbc9eb533a07c66a7",
      "max": 1565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c148d084abf84b338f42d12c302ba35b",
      "value": 1565
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
