{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GItxU96mTk16"
   },
   "source": [
    "# Tarea 6: Transformers aplicado a traducción y clasificación de textos\n",
    "## Curso: Procesamiento de Lenguaje Natural (NLP)\n",
    "## Maestría en Computación\n",
    "## Instituto Tecnológico de Costa Rica (ITCR)\n",
    "\n",
    "Medio de entrega:  TecDigital.\n",
    "\n",
    "Entregables: Un archivo jupyter con los ejercicios resueltos.\n",
    "\n",
    "Modo de trabajo: individual o en grupos de máximo dos personas.\n",
    "\n",
    "**Elaborado por**:\n",
    "\n",
    "\n",
    "*   Victoria Orozco Arias. Carnet $2022438528$\n",
    "*   Esteban Villalobos Gómez. Carnet $9913628$\n",
    "\n",
    "**Fecha de entrega:** 15/10/2024\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 1: Creación de un transformer para traducción de textos\n",
    "\n",
    "Este ejercicio consiste en crear de cero un modelo de transformer (codificador-decodificador) utilizando la biblioteca de PyTorch y la arquitectura básica vista en clase y que se describe en la publicación original \"Attention Is All You Need\" (Vaswani et al., 2017). El modelo debe ser entrenado para realizar traducciones de texto.\n",
    "\n",
    "\n",
    "El dataset a utilizar está disponible en Hugging Face en librakevin/opus_books_split 1y consiste en un conjunto de datos para realizar traducción de inglés a italiano. \n",
    "\n",
    "\n",
    "El conjunto de datos es muy simple y pequeño, contiene el texto en ingles y su traducción al italiano. Ejemplo: { \"en\": \"There was no possibility of taking a walk that day.\", \"it\": \"I. In quel giorno era impossibile passeggiare.\" }. Existe una versión más completa del conjunto de datos en https://huggingface.co/datasets/Helsinki-NLP/opus_books por si lo prefieren, esta incluye traducción al español.\n",
    "\n",
    "\n",
    "Deben entregar un cuaderno de Jupyter con el siguiente contenido:"
   ],
   "metadata": {
    "id": "yZSidYBewVhV"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Carga y pre-procesamiento de los datos\n",
    "\n",
    "  * (5 puntos) Procese el conjunto de datos (limpiar, tokenizar y realizar lo necesario\n",
    "llevar a cabo el ejercicio)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:02.669919Z",
     "start_time": "2024-10-12T04:52:00.718473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install --upgrade transformers datasets evaluate huggingface_hub accelerate>=0.26.0 tiktoken\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:03.704390Z",
     "start_time": "2024-10-12T04:52:03.694392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "print(accelerate.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:11.581279Z",
     "start_time": "2024-10-12T04:52:09.822103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = {'train': 'en-it/train-00000-of-00001.parquet', 'validation': 'en-it/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/librakevin/opus_books_split/\" + splits[\"train\"])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:11.940393Z",
     "start_time": "2024-10-12T04:52:11.925385Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Source: Project Gutenberg', 'it': 'Sou...\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}\n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...\n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}\n",
       "4  {'en': 'There was no possibility of taking a w..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Source: Project Gutenberg', 'it': 'Sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:14.036254Z",
     "start_time": "2024-10-12T04:52:14.023236Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.drop(df.index[0])",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:15.370744Z",
     "start_time": "2024-10-12T04:52:15.357745Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}\n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...\n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}\n",
       "4  {'en': 'There was no possibility of taking a w...\n",
       "5  {'en': 'We had been wandering, indeed, in the ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'en': 'We had been wandering, indeed, in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:43.805876Z",
     "start_time": "2024-10-12T04:52:31.927967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", model_max_length=750)\n",
    "\n",
    "# Extract the 'en' and 'it' fields and tokenize\n",
    "df['tokenized_en'] = df['translation'].apply(lambda x: tokenizer.encode(x['en'], return_tensors=\"pt\").to(device))\n",
    "df['tokenized_it'] = df['translation'].apply(lambda x: tokenizer.encode(x['it'], return_tensors=\"pt\").to(device))\n",
    "\n",
    "# Display the tokenized DataFrame\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation  \\\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}   \n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...   \n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}   \n",
       "4  {'en': 'There was no possibility of taking a w...   \n",
       "5  {'en': 'We had been wandering, indeed, in the ...   \n",
       "\n",
       "                                        tokenized_en  \\\n",
       "1  [[tensor(41083, device='cuda:0'), tensor(21566...   \n",
       "2  [[tensor(24453, device='cuda:0'), tensor(11404...   \n",
       "3  [[tensor(41481, device='cuda:0'), tensor(314, ...   \n",
       "4  [[tensor(1858, device='cuda:0'), tensor(373, d...   \n",
       "5  [[tensor(1135, device='cuda:0'), tensor(550, d...   \n",
       "\n",
       "                                        tokenized_it  \n",
       "1  [[tensor(41083, device='cuda:0'), tensor(21566...  \n",
       "2  [[tensor(24453, device='cuda:0'), tensor(11404...  \n",
       "3  [[tensor(30709, device='cuda:0'), tensor(36, d...  \n",
       "4  [[tensor(40, device='cuda:0'), tensor(13, devi...  \n",
       "5  [[tensor(14772, device='cuda:0'), tensor(23963...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>tokenized_en</th>\n",
       "      <th>tokenized_it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "      <td>[[tensor(41083, device='cuda:0'), tensor(21566...</td>\n",
       "      <td>[[tensor(41083, device='cuda:0'), tensor(21566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "      <td>[[tensor(24453, device='cuda:0'), tensor(11404...</td>\n",
       "      <td>[[tensor(24453, device='cuda:0'), tensor(11404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "      <td>[[tensor(41481, device='cuda:0'), tensor(314, ...</td>\n",
       "      <td>[[tensor(30709, device='cuda:0'), tensor(36, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "      <td>[[tensor(1858, device='cuda:0'), tensor(373, d...</td>\n",
       "      <td>[[tensor(40, device='cuda:0'), tensor(13, devi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'en': 'We had been wandering, indeed, in the ...</td>\n",
       "      <td>[[tensor(1135, device='cuda:0'), tensor(550, d...</td>\n",
       "      <td>[[tensor(14772, device='cuda:0'), tensor(23963...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Creación del modelo\n",
    "\n",
    "  * (20 puntos) Programe el codificador, el decodificador y todo lo necesario para implementar el transformer utilizando PyTorch."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# todo",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Experimentos\n",
    "\n",
    " * (1 punto) Separe las muestras en datos de entrenamiento y validación.\n",
    " * (5 puntos) Entrene un modelo.\n",
    " * (2 puntos) Grafique la curva de error, explique los resultados obtenidos y ajuste el modelo o el proceso de entrenamiento apropiadamente (por ejemplo el número de épocas).\n",
    " * (2 puntos) Evalúe el modelo resultante con los datos de prueba utilizando métricas como BertScore2 y METEOR3.\n",
    " * (2 puntos) Analice los resultados y presente al menos cuatro conclusiones.\n",
    " * (2 puntos) Todas las secciones del ejercicio deben estar bien documentadas."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split df into train and validate datasets, and convert them to torch tensors. 20% of the data is reserved for validation\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "validate_df = df.drop(train_df.index)\n",
    "\n",
    "# convert the dataframes to torch tensors\n",
    "train_en = torch.cat(train_df['tokenized_en'].tolist())\n",
    "train_it = torch.cat(train_df['tokenized_it'].tolist())\n",
    "validate_en = torch.cat(validate_df['tokenized_en'].tolist())\n",
    "validate_it = torch.cat(validate_df['tokenized_it'].tolist())\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "NLP_tarea_5_SVM_LSTM_VOEV.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
