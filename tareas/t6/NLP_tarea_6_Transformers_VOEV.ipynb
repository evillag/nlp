{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GItxU96mTk16"
   },
   "source": [
    "# Tarea 6: Transformers aplicado a traducción y clasificación de textos\n",
    "## Curso: Procesamiento de Lenguaje Natural (NLP)\n",
    "## Maestría en Computación\n",
    "## Instituto Tecnológico de Costa Rica (ITCR)\n",
    "\n",
    "Medio de entrega:  TecDigital.\n",
    "\n",
    "Entregables: Un archivo jupyter con los ejercicios resueltos.\n",
    "\n",
    "Modo de trabajo: individual o en grupos de máximo dos personas.\n",
    "\n",
    "**Elaborado por**:\n",
    "\n",
    "\n",
    "*   Victoria Orozco Arias. Carnet $2022438528$\n",
    "*   Esteban Villalobos Gómez. Carnet $9913628$\n",
    "\n",
    "**Fecha de entrega:** 15/10/2024\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 1: Creación de un transformer para traducción de textos\n",
    "\n",
    "Este ejercicio consiste en crear de cero un modelo de transformer (codificador-decodificador) utilizando la biblioteca de PyTorch y la arquitectura básica vista en clase y que se describe en la publicación original \"Attention Is All You Need\" (Vaswani et al., 2017). El modelo debe ser entrenado para realizar traducciones de texto.\n",
    "\n",
    "\n",
    "El dataset a utilizar está disponible en Hugging Face en librakevin/opus_books_split 1y consiste en un conjunto de datos para realizar traducción de inglés a italiano. \n",
    "\n",
    "\n",
    "El conjunto de datos es muy simple y pequeño, contiene el texto en ingles y su traducción al italiano. Ejemplo: { \"en\": \"There was no possibility of taking a walk that day.\", \"it\": \"I. In quel giorno era impossibile passeggiare.\" }. Existe una versión más completa del conjunto de datos en https://huggingface.co/datasets/Helsinki-NLP/opus_books por si lo prefieren, esta incluye traducción al español.\n",
    "\n",
    "\n",
    "Deben entregar un cuaderno de Jupyter con el siguiente contenido:"
   ],
   "metadata": {
    "id": "yZSidYBewVhV"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Carga y pre-procesamiento de los datos\n",
    "\n",
    "  * (5 puntos) Procese el conjunto de datos (limpiar, tokenizar y realizar lo necesario\n",
    "llevar a cabo el ejercicio)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:02.669919Z",
     "start_time": "2024-10-12T04:52:00.718473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install --upgrade transformers datasets evaluate huggingface_hub accelerate>=0.26.0 tiktoken\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:03.704390Z",
     "start_time": "2024-10-12T04:52:03.694392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "print(accelerate.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:11.581279Z",
     "start_time": "2024-10-12T04:52:09.822103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = {'train': 'en-it/train-00000-of-00001.parquet', 'validation': 'en-it/validation-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/librakevin/opus_books_split/\" + splits[\"train\"])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:11.940393Z",
     "start_time": "2024-10-12T04:52:11.925385Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Source: Project Gutenberg', 'it': 'Sou...\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}\n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...\n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}\n",
       "4  {'en': 'There was no possibility of taking a w..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Source: Project Gutenberg', 'it': 'Sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:14.036254Z",
     "start_time": "2024-10-12T04:52:14.023236Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.drop(df.index[0])",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:15.370744Z",
     "start_time": "2024-10-12T04:52:15.357745Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}\n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...\n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}\n",
       "4  {'en': 'There was no possibility of taking a w...\n",
       "5  {'en': 'We had been wandering, indeed, in the ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'en': 'We had been wandering, indeed, in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T04:52:43.805876Z",
     "start_time": "2024-10-12T04:52:31.927967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", model_max_length=750)\n",
    "\n",
    "# Extract the 'en' and 'it' fields and tokenize\n",
    "df['tokenized_en'] = df['translation'].apply(lambda x: tokenizer.encode(x['en'], return_tensors=\"pt\").to(device))\n",
    "df['tokenized_it'] = df['translation'].apply(lambda x: tokenizer.encode(x['it'], return_tensors=\"pt\").to(device))\n",
    "\n",
    "# Display the tokenized DataFrame\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         translation  \\\n",
       "1             {'en': 'Jane Eyre', 'it': 'Jane Eyre'}   \n",
       "2  {'en': 'Charlotte Bronte', 'it': 'Charlotte Br...   \n",
       "3           {'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}   \n",
       "4  {'en': 'There was no possibility of taking a w...   \n",
       "5  {'en': 'We had been wandering, indeed, in the ...   \n",
       "\n",
       "                                        tokenized_en  \\\n",
       "1  [[tensor(41083, device='cuda:0'), tensor(21566...   \n",
       "2  [[tensor(24453, device='cuda:0'), tensor(11404...   \n",
       "3  [[tensor(41481, device='cuda:0'), tensor(314, ...   \n",
       "4  [[tensor(1858, device='cuda:0'), tensor(373, d...   \n",
       "5  [[tensor(1135, device='cuda:0'), tensor(550, d...   \n",
       "\n",
       "                                        tokenized_it  \n",
       "1  [[tensor(41083, device='cuda:0'), tensor(21566...  \n",
       "2  [[tensor(24453, device='cuda:0'), tensor(11404...  \n",
       "3  [[tensor(30709, device='cuda:0'), tensor(36, d...  \n",
       "4  [[tensor(40, device='cuda:0'), tensor(13, devi...  \n",
       "5  [[tensor(14772, device='cuda:0'), tensor(23963...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>tokenized_en</th>\n",
       "      <th>tokenized_it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Jane Eyre', 'it': 'Jane Eyre'}</td>\n",
       "      <td>[[tensor(41083, device='cuda:0'), tensor(21566...</td>\n",
       "      <td>[[tensor(41083, device='cuda:0'), tensor(21566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'Charlotte Bronte', 'it': 'Charlotte Br...</td>\n",
       "      <td>[[tensor(24453, device='cuda:0'), tensor(11404...</td>\n",
       "      <td>[[tensor(24453, device='cuda:0'), tensor(11404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'CHAPTER I', 'it': 'PARTE PRIMA'}</td>\n",
       "      <td>[[tensor(41481, device='cuda:0'), tensor(314, ...</td>\n",
       "      <td>[[tensor(30709, device='cuda:0'), tensor(36, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'There was no possibility of taking a w...</td>\n",
       "      <td>[[tensor(1858, device='cuda:0'), tensor(373, d...</td>\n",
       "      <td>[[tensor(40, device='cuda:0'), tensor(13, devi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'en': 'We had been wandering, indeed, in the ...</td>\n",
       "      <td>[[tensor(1135, device='cuda:0'), tensor(550, d...</td>\n",
       "      <td>[[tensor(14772, device='cuda:0'), tensor(23963...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Creación del modelo\n",
    "\n",
    "  * (20 puntos) Programe el codificador, el decodificador y todo lo necesario para implementar el transformer utilizando PyTorch."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:08:30.680899Z",
     "start_time": "2024-10-12T05:08:30.657644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adaptado de https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:09:05.252496Z",
     "start_time": "2024-10-12T05:09:05.242984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:09:21.879288Z",
     "start_time": "2024-10-12T05:09:21.868015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:09:56.855664Z",
     "start_time": "2024-10-12T05:09:56.834568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:09:58.338270Z",
     "start_time": "2024-10-12T05:09:58.323234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:10:11.416938Z",
     "start_time": "2024-10-12T05:10:11.401920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:10:22.676299Z",
     "start_time": "2024-10-12T05:10:22.113386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Experimentos\n",
    "\n",
    " * (1 punto) Separe las muestras en datos de entrenamiento y validación.\n",
    " * (5 puntos) Entrene un modelo.\n",
    " * (2 puntos) Grafique la curva de error, explique los resultados obtenidos y ajuste el modelo o el proceso de entrenamiento apropiadamente (por ejemplo el número de épocas).\n",
    " * (2 puntos) Evalúe el modelo resultante con los datos de prueba utilizando métricas como BertScore2 y METEOR3.\n",
    " * (2 puntos) Analice los resultados y presente al menos cuatro conclusiones.\n",
    " * (2 puntos) Todas las secciones del ejercicio deben estar bien documentadas."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split df into train and validate datasets, and convert them to torch tensors. 20% of the data is reserved for validation\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "validate_df = df.drop(train_df.index)\n",
    "\n",
    "# convert the dataframes to torch tensors\n",
    "train_en = torch.cat(train_df['tokenized_en'].tolist())\n",
    "train_it = torch.cat(train_df['tokenized_it'].tolist())\n",
    "validate_en = torch.cat(validate_df['tokenized_en'].tolist())\n",
    "validate_it = torch.cat(validate_df['tokenized_it'].tolist())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate random sample data\n",
    "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-12T05:10:54.152719Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 8.685554504394531\n",
      "Epoch: 2, Loss: 8.546586990356445\n",
      "Epoch: 3, Loss: 8.4775972366333\n",
      "Epoch: 4, Loss: 8.420077323913574\n",
      "Epoch: 5, Loss: 8.364520072937012\n",
      "Epoch: 6, Loss: 8.293992042541504\n",
      "Epoch: 7, Loss: 8.222147941589355\n",
      "Epoch: 8, Loss: 8.133575439453125\n",
      "Epoch: 9, Loss: 8.048762321472168\n",
      "Epoch: 10, Loss: 7.971360206604004\n",
      "Epoch: 11, Loss: 7.890737056732178\n",
      "Epoch: 12, Loss: 7.810125350952148\n",
      "Epoch: 13, Loss: 7.72412109375\n",
      "Epoch: 14, Loss: 7.633805751800537\n",
      "Epoch: 15, Loss: 7.549288272857666\n",
      "Epoch: 16, Loss: 7.468044281005859\n",
      "Epoch: 17, Loss: 7.3885345458984375\n",
      "Epoch: 18, Loss: 7.307461738586426\n",
      "Epoch: 19, Loss: 7.226999759674072\n",
      "Epoch: 20, Loss: 7.1388044357299805\n",
      "Epoch: 21, Loss: 7.0613789558410645\n",
      "Epoch: 22, Loss: 6.97879695892334\n",
      "Epoch: 23, Loss: 6.909514427185059\n",
      "Epoch: 24, Loss: 6.833178997039795\n",
      "Epoch: 25, Loss: 6.75362491607666\n",
      "Epoch: 26, Loss: 6.674020290374756\n",
      "Epoch: 27, Loss: 6.602151393890381\n",
      "Epoch: 28, Loss: 6.5421881675720215\n",
      "Epoch: 29, Loss: 6.467689037322998\n",
      "Epoch: 30, Loss: 6.3850884437561035\n",
      "Epoch: 31, Loss: 6.3193440437316895\n",
      "Epoch: 32, Loss: 6.253485202789307\n",
      "Epoch: 33, Loss: 6.176854133605957\n",
      "Epoch: 34, Loss: 6.114675998687744\n",
      "Epoch: 35, Loss: 6.043901443481445\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src_data, tgt_data[:, :-1])\n",
    "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transformer.eval()\n",
    "\n",
    "# Generate random sample validation data\n",
    "val_src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "val_tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_output = transformer(val_src_data, val_tgt_data[:, :-1])\n",
    "    val_loss = criterion(val_output.contiguous().view(-1, tgt_vocab_size), val_tgt_data[:, 1:].contiguous().view(-1))\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "name": "NLP_tarea_5_SVM_LSTM_VOEV.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
